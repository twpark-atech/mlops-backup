# src/pipelines/silver_to_gold.py

import os
import argparse
from datetime import datetime, timedelta

from pyspark.sql import functions as F
from src.common.spark_session import create_spark

import psycopg2


def _get_env(name: str, default: str) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ì½ê¸° (ì—†ìœ¼ë©´ default)."""
    return os.environ.get(name, default)


def _delete_existing_partition(
    dt: str,
    table: str,
    host: str,
    port: str,
    db: str,
    user: str,
    password: str,
    date_col: str = "date",
) -> None:
    """
    ì¬ì‹¤í–‰ ì‹œ ì¤‘ë³µ ë°©ì§€ìš©: GOLD í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ë‚ ì§œ íŒŒí‹°ì…˜ì„ ë¯¸ë¦¬ ì‚­ì œ.
    """
    conn = None
    try:
        conn = psycopg2.connect(
            host=host,
            port=port,
            dbname=db,
            user=user,
            password=password,
        )
        conn.autocommit = True
        with conn.cursor() as cur:
            sql = f'DELETE FROM "{table}" WHERE "{date_col}" = %s'
            cur.execute(sql, (dt,))
        print(f'[SILVERâ†’GOLD] {table} ì—ì„œ date={dt} ê¸°ì¡´ í–‰ ì‚­ì œ ì™„ë£Œ')
    except Exception as e:
        print(f'[SILVERâ†’GOLD][WARN] date={dt} ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}')
    finally:
        if conn is not None:
            conn.close()


def run_its_traffic_silver_to_gold(start_date: str, end_date: str) -> None:
    """
    ITS 5ë¶„ ë‹¨ìœ„ êµí†µ ì†ë„ Silver â†’ Postgres GOLD ì ì¬
    """

    # ğŸ”¹ Spark ì„¸ì…˜ (S3 + JDBC ë“œë¼ì´ë²„ê°€ ì„¤ì •ëœ ìƒíƒœì—¬ì•¼ í•¨)
    spark = create_spark("SILVER_TO_GOLD_ITS_TRAFFIC_5MIN")

    # ğŸ”¹ Silver ìœ„ì¹˜ (MinIO / S3A)
    base_silver = "s3a://its/traffic/silver"

    # ğŸ”¹ Postgres ì ‘ì† ì •ë³´ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
    pg_host = _get_env("PG_HOST", "localhost")
    pg_port = _get_env("PG_PORT", "5431")
    pg_db = _get_env("PG_DB", "mlops")
    pg_user = _get_env("PG_USER", "postgres")
    pg_password = _get_env("PG_PASSWORD", "postgres")
    pg_table = _get_env("ITS_TRAFFIC_GOLD_TABLE", "its_traffic_5min_gold")

    jdbc_url = f"jdbc:postgresql://{pg_host}:{pg_port}/{pg_db}"

    start = datetime.strptime(start_date, "%Y%m%d")
    end = datetime.strptime(end_date, "%Y%m%d")

    cur = start
    while cur <= end:
        dt = cur.strftime("%Y%m%d")
        silver_path = f"{base_silver}/date={dt}"

        print(f"[SILVERâ†’GOLD] {dt} ì½ëŠ” ì¤‘: {silver_path}")

        try:
            df_silver = spark.read.parquet(silver_path)

            # âœ… ìŠ¤í‚¤ë§ˆ ì‚´ì§ ì •ë¦¬
            # - datetime: timestamp ê·¸ëŒ€ë¡œ ì‚¬ìš©
            # - linkid: string
            # - speed_mean / count ê°™ì€ ìˆ«ì ì»¬ëŸ¼ì€ double/long ìœ ì§€
            cols = df_silver.columns

            # ì»¬ëŸ¼ ì´ë¦„ ì˜ˆì‹œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ guard ê±¸ì–´ì„œ ì²˜ë¦¬
            # (bronze_to_silverì—ì„œ ì–´ë–¤ ì´ë¦„ ì¼ëŠ”ì§€ ë§ì¶°ì„œ í•„ìš”ì‹œ ì‚´ì§ ìˆ˜ì •í•˜ë©´ ë¨)
            rename_map = {}
            if "LINKID" in cols:
                rename_map["LINKID"] = "linkid"
            if "DATETIME_5MIN" in cols:
                rename_map["DATETIME_5MIN"] = "datetime"
            if "datetime_5min" in cols:
                rename_map["datetime_5min"] = "datetime"

            df_out = df_silver
            for src, dst in rename_map.items():
                df_out = df_out.withColumnRenamed(src, dst)

            # date ì»¬ëŸ¼ì€ GOLD í…Œì´ë¸” íŒŒí‹°ì…”ë‹ / ì¡°íšŒìš©ìœ¼ë¡œ í•˜ë‚˜ ë” ë„£ì–´ì¤Œ
            df_out = df_out.withColumn("date", F.lit(dt).cast("string"))

            # (ì„ íƒ) ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
            ordered_cols = []
            for c in ["date", "datetime", "linkid"]:
                if c in df_out.columns:
                    ordered_cols.append(c)
            # ë‚˜ë¨¸ì§€ ë©”íŠ¸ë¦­ ì»¬ëŸ¼ë“¤ ë’¤ì— ë¶™ì´ê¸°
            ordered_cols += [c for c in df_out.columns if c not in ordered_cols]
            df_out = df_out.select(*ordered_cols)

            # âœ… ì¬ì‹¤í–‰ ëŒ€ë¹„: í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ë¨¼ì € ì‚­ì œ
            _delete_existing_partition(
                dt=dt,
                table=pg_table,
                host=pg_host,
                port=pg_port,
                db=pg_db,
                user=pg_user,
                password=pg_password,
                date_col="date",
            )

            # âœ… Postgresì— append
            (
                df_out.write
                .mode("append")
                .format("jdbc")
                .option("url", jdbc_url)
                .option("dbtable", pg_table)
                .option("user", pg_user)
                .option("password", pg_password)
                .option("driver", "org.postgresql.Driver")
                .save()
            )

            print(f"[SILVERâ†’GOLD] {dt} â†’ {pg_table} ì ì¬ ì™„ë£Œ")

        except Exception as e:
            print(f"[SILVERâ†’GOLD][WARN] {dt} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        cur += timedelta(days=1)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job-name", required=True, help="ì˜ˆ: its_traffic_5min")
    parser.add_argument("--start-date", required=True, help="YYYYMMDD")
    parser.add_argument("--end-date", required=True, help="YYYYMMDD")
    args = parser.parse_args()

    if args.job_name == "its_traffic_5min":
        run_its_traffic_silver_to_gold(args.start_date, args.end_date)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” job-name: {args.job_name}")


if __name__ == "__main__":
    main()